{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "099d0f7e",
   "metadata": {},
   "source": [
    "# Data Download and Verification\n",
    "\n",
    "This notebook helps you download and verify public datasets for regulatory genomics modeling. It covers the DeepSEA training bundle, ENCODE, and Roadmap Epigenomics. Outputs are organized in `data/raw/` for downstream preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6d4440",
   "metadata": {},
   "source": [
    "## DeepSEA Training Bundle\n",
    "- [DeepSEA download page](http://deepsea.princeton.edu/help/)\n",
    "- Download the training bundle (large .tar.gz) manually or with the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4528bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSEA bundle already downloaded.\n",
      "Extracting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xk/dpfsy9813691nbbh305lfdjw0000gn/T/ipykernel_2347/1735500077.py:20: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(RAW)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete.\n",
      "DeepSEA files: []\n"
     ]
    }
   ],
   "source": [
    "import os, requests, tarfile, shutil\n",
    "from pathlib import Path\n",
    "RAW = Path('data/raw')\n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "deepsea_url = 'http://deepsea.princeton.edu/media/code/deepsea_train_bundle.v0.9.tar.gz'\n",
    "deepsea_tar = RAW / 'deepsea_train_bundle.v0.9.tar.gz'\n",
    "if not deepsea_tar.exists():\n",
    "    print('Downloading DeepSEA training bundle...')\n",
    "    r = requests.get(deepsea_url, stream=True)\n",
    "    with open(deepsea_tar, 'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)\n",
    "    print('Download complete.')\n",
    "else:\n",
    "    print('DeepSEA bundle already downloaded.')\n",
    "# Extract\n",
    "deepsea_dir = RAW / 'deepsea_train_bundle'\n",
    "if not deepsea_dir.exists():\n",
    "    print('Extracting...')\n",
    "    with tarfile.open(deepsea_tar, 'r:gz') as tar:\n",
    "        tar.extractall(RAW)\n",
    "    print('Extraction complete.')\n",
    "else:\n",
    "    print('DeepSEA bundle already extracted.')\n",
    "# List contents\n",
    "print('DeepSEA files:', list(deepsea_dir.glob('*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73846e9f",
   "metadata": {},
   "source": [
    "## ENCODE Data\n",
    "- [ENCODE Project](https://www.encodeproject.org/)\n",
    "- Use the ENCODE REST API to search and download metadata or files. See [API docs](https://www.encodeproject.org/help/rest-api/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735f01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Example: Search for DNase-seq experiments in human (GRCh38)\n",
    "search_url = 'https://www.encodeproject.org/search/'\n",
    "params = {\n",
    "    'type': 'experiment',\n",
    "    'assay_title': 'DNase-seq',\n",
    "    'assembly': 'GRCh38',\n",
    "    'status': 'released',\n",
    "    'limit': 5,\n",
    "    'format': 'json'\n",
    "}\n",
    "r = requests.get(search_url, params=params, headers={'accept': 'application/json'})\n",
    "results = r.json()['@graph']\n",
    "for exp in results:\n",
    "    print(exp['accession'], exp['assay_title'], exp['biosample_term_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ffec5e",
   "metadata": {},
   "source": [
    "## Roadmap Epigenomics Data\n",
    "- [Roadmap Epigenomics Portal](https://egg2.wustl.edu/roadmap/web_portal/)\n",
    "- Data is available via web portal, AWS Open Data, and GEO. Download manually or script as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab656aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See portal for available files: https://egg2.wustl.edu/roadmap/web_portal/\n"
     ]
    }
   ],
   "source": [
    "# Example: List available Roadmap files (manual download recommended for large files)\n",
    "print('See portal for available files: https://egg2.wustl.edu/roadmap/web_portal/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e6169",
   "metadata": {},
   "source": [
    "## Verification\n",
    "- Check that expected files exist in `data/raw/` and print their sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6f4932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw/deepsea_train 0 KB\n",
      "data/raw/coords.tsv 0 KB\n",
      "data/raw/reference.fa.fai 0 KB\n",
      "data/raw/deepsea_train_bundle.v0.9.tar.gz 3732296 KB\n",
      "data/raw/reference.fa 195 KB\n"
     ]
    }
   ],
   "source": [
    "for f in RAW.glob('*'):\n",
    "    print(f, f.stat().st_size // 1024, 'KB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
