{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 – Data Preprocessing\n",
    "\n",
    "This notebook builds the data pipeline:\n",
    "- Load coordinates/labels (CSV/TSV/BED-like)\n",
    "- Extract ±1kb sequences from a reference FASTA\n",
    "- One-hot encode and save train/val/test arrays (.npz)\n",
    "\n",
    "**Inputs expected:**\n",
    "- `data/raw/reference.fa` (+ `.fai` index)\n",
    "- `data/raw/coords.tsv` with columns: `chrom start end label`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe7cad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# Ensure project root (that contains 'src/') is on sys.path\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT/'src').exists():\n",
    "\tROOT = ROOT.parent\n",
    "if (ROOT/'src').exists() and str(ROOT) not in sys.path:\n",
    "\tsys.path.insert(0, str(ROOT))\n",
    "\n",
    "from src.data_utils import extract_sequence_window, load_coordinates, one_hot_encode, train_val_test_split\n",
    "\n",
    "RAW = Path('data/raw')\n",
    "PROC = Path('data/processed')\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FASTA = RAW/'reference.fa'  # <-- place your hg19/hg38 FASTA here\n",
    "COORDS = RAW/'coords.tsv'   # <-- provide your coordinate+label file here\n",
    "WINDOW = 1000  # +/- 1kb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ad6875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chrom  start    end  label\n",
      "0  chr1   9950  10050      0\n",
      "1  chr1  10950  11050      1\n",
      "2  chr1  11950  12050      0\n",
      "3  chr1  12950  13050      1\n",
      "4  chr1  13950  14050      0\n",
      "Total rows: 50\n"
     ]
    }
   ],
   "source": [
    "# 1) Load coordinates\n",
    "\n",
    "df = load_coordinates(str(COORDS))\n",
    "print(df.head())\n",
    "print('Total rows:', len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "962c6220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA exists: True | COORDS exists: True\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from pathlib import Path\n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "if not FASTA.exists():\n",
    "    with open(FASTA, 'w') as fh:\n",
    "        fh.write('>chr1\\n')\n",
    "        # 200,000bp of repeating pattern to allow many windows\n",
    "        fh.write(('ACGT' * 50000) + '\\n')\n",
    "if not (RAW/'reference.fa.fai').exists():\n",
    "    # Build a minimal 1-line index for naive users; real workflows should run: samtools faidx reference.fa\n",
    "    with open(RAW/'reference.fa.fai', 'w') as fh:\n",
    "        # chrom length offset line_bases line_width\n",
    "        fh.write('chr1\\t200000\\t6\\t200000\\t200001\\n')\n",
    "if not COORDS.exists():\n",
    "    import pandas as pd, numpy as np\n",
    "    centers = np.arange(10_000, 10_000 + 50*1000, 1000)  # 50 examples spaced\n",
    "    df_toy = pd.DataFrame({\n",
    "        'chrom': 'chr1',\n",
    "        'start': centers - 50,\n",
    "        'end': centers + 50,\n",
    "        'label': (np.arange(len(centers)) % 2).astype(int)\n",
    "    })\n",
    "    df_toy.to_csv(COORDS, sep='\\t', index=False)\n",
    "print('FASTA exists:', FASTA.exists(), '| COORDS exists:', COORDS.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (50, 2000, 4) y shape: (50,)\n"
     ]
    }
   ],
   "source": [
    "# 2) Extract sequences and one-hot encode\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "for _, row in df.iterrows():\n",
    "    chrom, start, end, label = row['chrom'], int(row['start']), int(row['end']), int(row['label'])\n",
    "    center = (start + end)//2\n",
    "    seq = extract_sequence_window(str(FASTA), chrom, center, window=WINDOW)\n",
    "    X_list.append(one_hot_encode(seq))\n",
    "    y_list.append(label)\n",
    "\n",
    "X = np.stack(X_list, axis=0)  # shape: (N, 2*WINDOW, 4)\n",
    "y = np.asarray(y_list, dtype=np.int64)\n",
    "print('X shape:', X.shape, 'y shape:', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/processed/: train.npz, val.npz, test.npz\n"
     ]
    }
   ],
   "source": [
    "# 3) Train/Val/Test split and save\n",
    "\n",
    "train_idx, val_idx, test_idx = train_val_test_split(len(y), val_frac=0.1, test_frac=0.1, seed=42)\n",
    "\n",
    "np.savez(PROC/'train.npz', X=X[train_idx], y=y[train_idx])\n",
    "np.savez(PROC/'val.npz', X=X[val_idx], y=y[val_idx])\n",
    "np.savez(PROC/'test.npz', X=X[test_idx], y=y[test_idx])\n",
    "\n",
    "print('Saved to data/processed/: train.npz, val.npz, test.npz')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
